<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation</title>

    <link rel="stylesheet" href="bulma.0.9.0.min.css">
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script>
      function change_img_url(data, tag) {
        var x = document.getElementById(data + "-" + tag + "-slider").value;
        document.getElementById(data + "-" + tag + "-img").src = "imgs/" + tag + "-egs-" + data + "-" + x + ".jpg";
      }
    </script>
    <style>
      var {
        font-family: monospace;
        font-style: normal;
      }
    </style>
  </head>
  <body>
  <section class="section">
    <div class="container">
      <h1 class="title">
        What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation
      </h1>
      <h2 class="subtitle">
        <a href="http://vtaly.net/">Vitaly Feldman</a><sup>♮</sup>,
        <a href="http://pluskid.org/">Chiyuan Zhang</a><sup>♮</sup>
        <span class="has-text-gray" style="float: right;"><sup>♮</sup> Equal contribution</span>
      </h2>

      <div class="field is-grouped is-grouped-multiline">
        <div class="control">
            <a href="http://vtaly.net/papers/FZ_Infl_mem.pdf">
              <div class="tags has-addons">
                <span class="tag is-dark">
                  <span class="icon"><i class="fas fa-file"></i></span>
                  &nbsp;Paper
                </span>
                <span class="tag is-primary">PDF</span>
              </div>
            </a>
        </div>
        <!--
        <div class="control">
            <a href="#">
              <div class="tags has-addons">
                <span class="tag is-dark">
                  <span class="icon"><i class="fas fa-code-branch"></i></span>
                  &nbsp;Code
                </span>
                <span class="tag is-info">coming soon</span>
              </div>
            </a>
        </div>
        -->
        <div class="control">
            <a href="#imagenet-dl">
              <div class="tags has-addons">
                <span class="tag is-dark">
                  <span class="icon"><i class="fas fa-download"></i></span>
                  &nbsp;scores
                </span>
                <span class="tag is-success">ImageNet</span>
              </div>
            </a>
        </div>
        <div class="control">
            <a href="#cifar100-dl">
              <div class="tags has-addons">
                <span class="tag is-dark">
                  <span class="icon"><i class="fas fa-download"></i></span>
                  &nbsp;scores
                </span>
                <span class="tag is-success">CIFAR-100</span>
              </div>
            </a>
        </div>
      </div>

      <div class="content">
        <p>
          <b>Abstract</b>:
          Deep learning algorithms are well-known to have a propensity for fitting the training data very well and often fit
          even outliers and mislabeled data points. Such fitting requires memorization of training data labels, a phenomenon
          that has attracted significant research interest but has not been given a compelling explanation so far. A recent work
          of Feldman [<a href="https://arxiv.org/abs/1906.05271">Fel19</a>] proposes a theoretical explanation for this phenomenon based on a combination of two insights.
          First, natural image and data distributions are (informally) known to be long-tailed, that is have a significant fraction
          of rare and atypical examples. Second, in a simple theoretical model such memorization is necessary for achieving
          close-to-optimal generalization error when the data distribution is long-tailed. However, no direct empirical evidence
          for this explanation or even an approach for obtaining such evidence were given.
        </p>
        <p>
          In this work we design experiments to test the key ideas in this theory. The experiments require estimation
          of the influence of each training example on the accuracy at each test example as well as memorization values of
          training examples. Estimating these quantities directly is computationally prohibitive but we show that closely-related
          subsampled influence and memorization values can be estimated much more efficiently. Our experiments demonstrate
          the significant benefits of memorization for generalization on several standard benchmarks. They also provide
          quantitative and visually compelling evidence for the theory put forth in [<a href="https://arxiv.org/abs/1906.05271">Fel19</a>].
        </p>

        <h1 class="title is-4 mb-2" id="imagenet-dl">ImageNet Pre-computed Memorization and Influence Value Estimates</h1>
        <p>
          We provide pre-computed memorization and influence value estimates on ImageNet for download here. The estimates
          are computed by training 2,000 ResNet-50 models, each on a random 70% subset of the full ImageNet training set.
          <ul>
            <li>
              <a href="data/imagenet_high_infl_pairs_infl0.15_mem0.25.npz">High-influence pairs</a>
              contains four arrays of equal length. <code>tr_idx</code> and <code>tt_idx</code> contains the
              index of the training and test examples, respectively, from each of the selected high-influence
              pairs. <code>infl</code> contains the influence value estimates of each pair, and <code>mem</code> contains
              the memorization value estimates of the training example in each of the selected pairs.
            </li>
            <li>
              <a href="data/imagenet_index.npz">ImageNet index</a> contains indexing information. Since there is
              no pre-defined order of the ImageNet images, we choose an arbitrary data order in our experiments.
              In this file, we provide the image filenames and labels listed by the data order in our experiments
              to help identifying the images associated with each influence and memorization value estimates. In particular,
              <code>tr_filenames</code> and <code>tr_labels</code> contains the filenames and labels of the training set.
              <code>tt_filenames</code> and <code>tt_labels</code> contains the filenames and labels of the test set.
              We also provide <code>tr_mem</code> which contains the memorization value estimates for all the training examples.
            </li>
            <li>
              <p>Class-wise influence matrices contains the
              <var>n_train</var>-by-<var>n_test</var> influence matrices for each class. Because the influence matrix over the
              entire training and test set is too big (250 GB+), we only provide the per-class influence matrices. For
              each class <code>K</code>, the array <code>tr_classidx_{K}</code> and <code>tt_classidx_{K}</code> provides
              the index of examples that belong to class <code>K</code> in the training set and test set, respectively.
              The value <code>infl_matrix_class{K}[i, j]</code> is the influence value of the <code>i</code>-th training
              example in class <code>K</code> on the <code>j</code>-th test example in class <code>K</code>.
              </p>
              <p>
                Due to the single-file-size limit of 100 MB, we split this file into
                <a href="data/imagenet_infl_matrix_split_aa.bin">part-1</a>,
                <a href="data/imagenet_infl_matrix_split_ab.bin">part-2</a>, and
                <a href="data/imagenet_infl_matrix_split_ac.bin">part-3</a>. The full <code>.npz</code> file
                can be reconstructed by concatenating the parts together:
                <pre>cat imagenet_infl_matrix_split_*.bin > imagenet_infl_matrix.npz</pre>
                The md5sum for the concatenated file is <code>20290f49a0468de7973892dc47f85e54</code>.
              </p>
            </li>
          </ul>
        </p>

        <h1 class="title is-4 mb-2" id="cifar100-dl">CIFAR-100 Pre-computed Memorization and Influence Value Estimates</h1>
        <p>
          We provide pre-computed memorization and influence value estimates on CIFAR-100 for download here. The estimates
          are computed by training 4,000 ResNet-50 models, each on a random 70% subset of the full CIFAR-100 training set.
          The estimates are provided in the original data order from the
          <a href="https://www.cs.toronto.edu/~kriz/cifar.html">official CIFAR-100 website</a>. We also provide
          <code>tr_labels</code> and <code>tt_labels</code> to help sanity check the data ordering.
          <ul>
            <li>
              <a href="data/cifar100_high_infl_pairs_infl0.15_mem0.25.npz">High-influence pairs</a>
              contains four arrays of equal length. <code>tr_idx</code> and <code>tt_idx</code> contains the
              index of the training and test examples, respectively, from each of the selected high-influence
              pairs. <code>infl</code> contains the influence estimates for all pairs, and <code>mem</code> contains
              the memorization value estimates of the training example in each of the selected pairs.
            </li>
            <li>
              <a href="data/cifar100_infl_matrix.npz">Class-wise influence matrices</a> contains the
              <var>n_train</var>-by-<var>n_test</var> influence matrices for each class <code>K</code>
              in the array with name <code>infl_matrix_class{K}</code>. The array <code>tr_classidx_{K}</code>
              and <code>tt_classidx_{K}</code> provides the index of examples that belong to class <code>K</code>
              in the training set and test set, respectively. <code>tr_labels</code> and <code>tt_labels</code>
              provide the labels on the training set and test set, respectively, to help sanity check the data ordering.
              Finally, <code>tr_mem</code> contains the memorization value estimates for all the training examples.
            </li>
          </ul>
        </p>
      </div>
    </div>
  </section>
  <section class="section pt-1">
    <div class="container">
      <h1 class="title is-4 mb-2">Memorization Value Examples</h1>
      <p class="mb-4">
        We show a histogram of the memorization value estimates of all the training examples.
        Use the slider below to select example visualizations around different memorization values 
        for a random subset of classes. The caption on top of each image shows the memorization value estimate
        of that image.
      </p>
    </div>
    <div class="container">
      <figure class="image is-fullwidth">
        <img src="imgs/memorization-hist-imagenet-18bins.svg">
      </figure>
      <article class="media">
        <div class="media-left">
          <span style="width: 3em; display: block;"></span>
        </div>
        <div class="media-content">
          <form style="width: 100%;">
            <input type="range" min="0" max="4" value="0" step="1" id="imagenet-mem-slider"
                   style="width: 100%;" onchange="change_img_url('imagenet', 'mem')">
          </form>
        </div>
      </article>
      <figure class="image is-fullwidth">
        <img id="imagenet-mem-img" src="imgs/mem-egs-imagenet-2.jpg">
      </figure>
    </div>
  </section>
  <section class="section pt-1">
    <div class="container">
      <h1 class="title is-4 mb-2">High-Influence Value Examples</h1>
      <p class="mb-4">
        We show a histogram of the influence value estimates of selected <em>high-influence pairs</em>
        (<var>mem</var> &GreaterEqual; 0.25, <var>infl</var> &GreaterEqual; 0.15,
        see <a href="http://vtaly.net/papers/FZ_Infl_mem.pdf">the paper</a> for more details).
        Use the slider below to select example visualizations around different values of influence estimates.
        In each row of the visualization, the first column shows an image from the training set (the caption on the top of the
        image shows the <em>memorization value estimate</em>). The
        remaining columns show images from the test set, ranked by the <em>influence value estimate</em> (also shown in the caption).
        So the first two images in each row form a <em>high-influence pair</em>.
      </p>
    </div>
    <div class="container">
      <figure class="image is-fullwidth">
        <img src="imgs/influence-hist-imagenet-18bins.svg">
      </figure>
      <article class="media">
        <div class="media-left">
          <span style="width: 3em; display: block;"></span>
        </div>
        <div class="media-content">
          <form style="width: 100%;">
            <input type="range" min="0" max="13" value="10" step="1" id="imagenet-influence-slider"
                   style="width: 100%;" onchange="change_img_url('imagenet', 'influence')">
          </form>
        </div>
      </article>
      <figure class="image is-fullwidth">
        <img id="imagenet-influence-img" src="imgs/influence-egs-imagenet-10.jpg">
      </figure>
    </div>
  </section>

  </body>
</html>
